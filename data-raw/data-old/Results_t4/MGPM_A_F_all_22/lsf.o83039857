Sender: LSF System <lsfadmin@eu-c7-072-06>
Subject: Job 83039857: <sh R --vanilla --slave -f ../../DetectShifts_t4_MGPM_A_F_all.R --args 22> in cluster <euler> Exited

Job <sh R --vanilla --slave -f ../../DetectShifts_t4_MGPM_A_F_all.R --args 22> was submitted from host <eu-login-01-ng> by user <vmitov> in cluster <euler> at Sat Jan 12 20:57:43 2019
Job was executed on host(s) <5*eu-c7-072-06>, in queue <normal.24h>, as user <vmitov> in cluster <euler> at Sat Jan 12 21:40:12 2019
                            <6*eu-c7-078-03>
                            <8*eu-c7-066-11>
                            <8*eu-c7-067-05>
                            <8*eu-c7-088-07>
                            <8*eu-c7-086-02>
                            <8*eu-c7-070-11>
                            <8*eu-c7-077-02>
                            <8*eu-c7-078-01>
                            <5*eu-c7-069-16>
                            <8*eu-c7-088-09>
                            <8*eu-c7-068-12>
                            <8*eu-c7-068-07>
                            <4*eu-c7-079-05>
</cluster/home/vmitov> was used as the home directory.
</cluster/home/vmitov/MGPMSimulations/data-raw/Results_t4/MGPM_A_F_all_22> was used as the working directory.
Started at Sat Jan 12 21:40:12 2019
Terminated at Sat Jan 12 23:37:27 2019
Results reported at Sat Jan 12 23:37:27 2019

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
sh R --vanilla --slave -f ../../DetectShifts_t4_MGPM_A_F_all.R --args 22
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   701747.00 sec.
    Max Memory :                                 25499 MB
    Average Memory :                             23261.96 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               76901.00 MB
    Max Swap :                                   -
    Max Processes :                              116
    Max Threads :                                317
    Run time :                                   7041 sec.
    Turnaround time :                            9584 sec.

The output (if any) follows:

Loading required package: Rcpp
Loading required package: doMPI
Loading required package: foreach
Loading required package: iterators
Loading required package: Rmpi
Master processor name: eu-c7-072-06; nodename: eu-c7-072-06
Size of MPI universe: 1
Spawning 99 workers using the command:
  /cluster/apps/r/3.4.0_openblas/x86_64/lib64/R/bin/Rscript /cluster/apps/r/3.4.0_openblas/x86_64/lib64/R/library/doMPI/RMPIworker.R WORKDIR=/cluster/home/vmitov/MGPMSimulations/data-raw/Results_t4/MGPM_A_F_all_22 LOGDIR=/cluster/home/vmitov/MGPMSimulations/data-raw/Results_t4/MGPM_A_F_all_22 MAXCORES=1 COMM=3 INTERCOMM=4 MTAG=10 WTAG=11 INCLUDEMASTER=TRUE BCAST=TRUE VERBOSE=TRUE
	99 slaves are spawned successfully. 0 failed.
--------------------------------------------------------------------------
An MPI process has executed an operation involving a call to the
"fork()" system call to create a child process.  Open MPI is currently
operating in a condition that could result in memory corruption or
other system errors; your MPI job may hang, crash, or produce silent
data corruption.  The use of fork() (or system() or other calls that
create child processes) is strongly discouraged.  

The process that invoked fork was:

  Local host:          eu-c7-079-05 (PID 45835)
  MPI_COMM_WORLD rank: 97

If you are *absolutely sure* that your application will successfully
and correctly survive a call to fork(), you may disable this warning
by setting the mpi_warn_on_fork MCA parameter to 0.
--------------------------------------------------------------------------
$PCMBase.Value.NA
[1] -1e+20

$PCMBase.Errors.As.Warnings
[1] TRUE

$PCMBase.Threshold.Lambda_ij
[1] 1e-08

$PCMBase.Threshold.EV
[1] 1e-07

$PCMBase.Threshold.SV
[1] 1e-06

$PCMBase.Threshold.Skip.Singular
[1] 1e-04

$PCMBase.Skip.Singular
[1] TRUE

$PCMBase.Tolerance.Symmetric
[1] 1e-08

$PCMBase.Lmr.mode
[1] 11

$PCMBase.ParamValue.LowerLimit.NonNegativeDiagonal
[1] 0

$PCMBase.ParamValue.LowerLimit
[1] -10

$PCMBase.ParamValue.UpperLimit
[1] 10

Initiating tableFits...
Step 1: Performing fits on 6  clades;  36  model mappings altogether...
[eu-c7-072-06:05569] 98 more processes have sent help message help-mpi-runtime.txt / mpi_init:warn-fork
[eu-c7-072-06:05569] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Step 2: Perform a recursive clade partition search of an optimal mixed model...
Step 2.1: Initiated queue of partition root nodes with the root of the original tree...
Step 2.2: headQPR= 1 : bestPartition / mapping / score: ( 81 ) / ( B ) /  676.7951  ; 
  Remaining queue:
Empty data.table (0 rows) of 5 cols: level,node,partitionParentNode,partInit,partCurrent
Performing clade-partitioning at partitionRootLabel= 81 ; partitionRootLevel= 1 
Step 2.3: numTips in subtree =  80 
Step 2.5: List of partitions of the tree:
81
81, 129
81, 128
81, 122
81, 121
81, 121, 129
81, 101
81, 101, 129
81, 101, 128
81, 101, 122
Step 2.6: Preparing allowed model-types for each clade-partition
listAllowedModelTypes:
 `81`: A, B, C, D, E, F
`129`: A, B, C, D, E, F
`128`: A, B, C, D, E, F
`122`: A, B, C, D, E, F
`121`: A, B, C, D, E, F
`101`: A, B, C, D, E, F
Error in checkCluster(cl) : not a valid cluster
Calls: <Anonymous> -> defaultCluster -> checkCluster
Execution halted
