Sender: LSF System <lsfadmin@eu-a6-004-01>
Subject: Job 83040201: <sh R --vanilla --slave -f ../../DetectShifts_t4_MGPM_SCALAROU_all.R --args 122> in cluster <euler> Exited

Job <sh R --vanilla --slave -f ../../DetectShifts_t4_MGPM_SCALAROU_all.R --args 122> was submitted from host <eu-login-01-ng> by user <vmitov> in cluster <euler> at Sat Jan 12 21:01:40 2019
Job was executed on host(s) <4*eu-a6-004-01>, in queue <normal.24h>, as user <vmitov> in cluster <euler> at Sun Jan 13 04:28:47 2019
                            <8*eu-a6-002-05>
                            <8*eu-a6-002-06>
                            <4*eu-a6-012-06>
                            <7*eu-a6-009-12>
                            <8*eu-a6-001-12>
                            <8*eu-a6-001-04>
                            <6*eu-a6-008-02>
                            <5*eu-a6-008-15>
                            <5*eu-a6-008-23>
                            <5*eu-a6-010-03>
                            <4*eu-a6-012-12>
                            <4*eu-a6-010-16>
                            <4*eu-a6-012-09>
                            <4*eu-a6-011-11>
                            <4*eu-a6-008-22>
                            <4*eu-a6-009-17>
                            <4*eu-a6-010-05>
                            <4*eu-a6-009-13>
</cluster/home/vmitov> was used as the home directory.
</cluster/home/vmitov/MGPMSimulations/data-raw/Results_t4/MGPM_SCALAROU_all_122> was used as the working directory.
Started at Sun Jan 13 04:28:47 2019
Terminated at Sun Jan 13 05:22:02 2019
Results reported at Sun Jan 13 05:22:02 2019

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
sh R --vanilla --slave -f ../../DetectShifts_t4_MGPM_SCALAROU_all.R --args 122
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   317011.00 sec.
    Max Memory :                                 19196 MB
    Average Memory :                             17754.94 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               83204.00 MB
    Max Swap :                                   -
    Max Processes :                              121
    Max Threads :                                322
    Run time :                                   3195 sec.
    Turnaround time :                            30022 sec.

The output (if any) follows:

Loading required package: Rcpp
Loading required package: doMPI
Loading required package: foreach
Loading required package: iterators
Loading required package: Rmpi
Master processor name: eu-a6-004-01; nodename: eu-a6-004-01
Size of MPI universe: 1
Spawning 99 workers using the command:
  /cluster/apps/r/3.4.0_openblas/x86_64/lib64/R/bin/Rscript /cluster/apps/r/3.4.0_openblas/x86_64/lib64/R/library/doMPI/RMPIworker.R WORKDIR=/cluster/home/vmitov/MGPMSimulations/data-raw/Results_t4/MGPM_SCALAROU_all_122 LOGDIR=/cluster/home/vmitov/MGPMSimulations/data-raw/Results_t4/MGPM_SCALAROU_all_122 MAXCORES=1 COMM=3 INTERCOMM=4 MTAG=10 WTAG=11 INCLUDEMASTER=TRUE BCAST=TRUE VERBOSE=TRUE
	99 slaves are spawned successfully. 0 failed.
--------------------------------------------------------------------------
An MPI process has executed an operation involving a call to the
"fork()" system call to create a child process.  Open MPI is currently
operating in a condition that could result in memory corruption or
other system errors; your MPI job may hang, crash, or produce silent
data corruption.  The use of fork() (or system() or other calls that
create child processes) is strongly discouraged.  

The process that invoked fork was:

  Local host:          eu-a6-012-06 (PID 7498)
  MPI_COMM_WORLD rank: 21

If you are *absolutely sure* that your application will successfully
and correctly survive a call to fork(), you may disable this warning
by setting the mpi_warn_on_fork MCA parameter to 0.
--------------------------------------------------------------------------
$PCMBase.Value.NA
[1] -1e+20

$PCMBase.Errors.As.Warnings
[1] TRUE

$PCMBase.Threshold.Lambda_ij
[1] 1e-08

$PCMBase.Threshold.EV
[1] 1e-07

$PCMBase.Threshold.SV
[1] 1e-06

$PCMBase.Threshold.Skip.Singular
[1] 1e-04

$PCMBase.Skip.Singular
[1] TRUE

$PCMBase.Tolerance.Symmetric
[1] 1e-08

$PCMBase.Lmr.mode
[1] 11

$PCMBase.ParamValue.LowerLimit.NonNegativeDiagonal
[1] 0

$PCMBase.ParamValue.LowerLimit
[1] -10

$PCMBase.ParamValue.UpperLimit
[1] 10

Initiating tableFits...
Step 1: Performing fits on 11  clades;  11  model mappings altogether...
[eu-a6-004-01:70082] 98 more processes have sent help message help-mpi-runtime.txt / mpi_init:warn-fork
[eu-a6-004-01:70082] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Step 2: Perform a recursive clade partition search of an optimal mixed model...
Step 2.1: Initiated queue of partition root nodes with the root of the original tree...
Step 2.2: headQPR= 1 : bestPartition / mapping / score: ( 81 ) / (  ) /  476.7435  ; 
  Remaining queue:
Empty data.table (0 rows) of 5 cols: level,node,partitionParentNode,partInit,partCurrent
Performing clade-partitioning at partitionRootLabel= 81 ; partitionRootLevel= 1 
Step 2.3: numTips in subtree =  80 
Step 2.5: List of partitions of the tree:
81
81, 126
81, 125
81, 124
81, 123
81, 122
81, 105
81, 105, 126
81, 105, 125
81, 105, 124
81, 104
81, 104, 126
81, 104, 125
81, 104, 124
81, 84
81, 84, 126
81, 84, 125
81, 84, 124
81, 84, 123
81, 84, 122
81, 83
81, 83, 126
81, 83, 125
81, 83, 124
81, 83, 123
81, 82
81, 82, 126
81, 82, 125
81, 82, 124
Step 2.6: Preparing allowed model-types for each clade-partition
listAllowedModelTypes:
 `81`: 
`126`: 
`125`: 
`124`: 
`123`: 
`122`: 
`105`: 
`104`: 
`84`: 
`83`: 
`82`: 
Error in checkCluster(cl) : not a valid cluster
Calls: <Anonymous> -> defaultCluster -> checkCluster
Execution halted
